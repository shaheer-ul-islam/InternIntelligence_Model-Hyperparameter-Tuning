## **Random Forest & XGBoost  Model Performance Evaluation & Hyperparameter Tuning**

## ğŸ“Œ Overview

This project focuses on evaluating the performance of an XGBoost model using cross-validation and key classification metrics (accuracy, precision, recall, and F1-score). Additionally, it includes hyperparameter tuning to improve the model and a visualization of performance differences.

## ğŸš€ Project Features

Base Model Training & Evaluation: Initial performance analysis using default XGBoost settings.

Hyperparameter Tuning: Optimization using GridSearchCV, Random Search, Bayesian Search, and Optuna.

Performance Metrics: Accuracy, Precision, Recall, and F1-Score comparisons before and after tuning.


## ğŸ› ï¸ Tech Stack

Programming Language: Python ğŸ

Libraries Used:

**xgboost**

sklearn

matplotlib

seaborn

numpy

optuna

## ğŸ“‚ Project Structure

ğŸ“¦ XGBoost-Model-Tuning
 â”£ ğŸ“œ heart_disease.ipynb  # Model training, evaluation & tuning
 â”£ ğŸ“œ Model_Tuning_and_Performance_Evaluation.docx
 â”£ ğŸ“œ README.md  # Project Documentation



## ğŸ“Š Results & Insights

| Model                           | Accuracy | Precision | Recall  | F1 Score |
|---------------------------------|----------|-----------|---------|----------|
| **XGBoost (Base)**              | 0.8598   | 0.8652    | 0.8598  | 0.8604   |
| **Random Forest (Base)**        | 0.9085   | 0.9110    | 0.9085  | 0.9077   |
| **XGBoost (Random Search)**     | 0.8659   | 0.8719    | 0.8659  | 0.8650   |
| **XGBoost (Grid Search)**       | 0.8476   | 0.8540    | 0.8476  | 0.8481   |
| **XGBoost (Bayes Search)**      | 0.8780   | 0.8790    | 0.8780  | 0.8776   |
| **XGBoost (Optuna)**            | 0.8537   | 0.8551    | 0.8537  | 0.8530   |
| **Random Forest (Random Search)** | 0.8841 | 0.8886    | 0.8841  | 0.8835   |
| **Random Forest (Grid Search)** | 0.8720   | 0.8741    | 0.8720  | 0.8716   |
| **Random Forest (Bayes Search)** | 0.8902  | 0.8952    | 0.8902  | 0.8909   |
| **Random Forest (Optuna)**      | 0.8659   | 0.8674    | 0.8659  | 0.8653   |


ğŸ”¹ Hyperparameter tuning significantly improves model performance.

## ğŸ“¢ About the Internship

This project is part of the Intern Intelligence ML Internship, designed to enhance machine learning skills through hands-on experience.

ğŸ”— [Intern Intelligence LinkedIn](https://www.linkedin.com/company/intern-intelligence/)

## ğŸ“¬ Connect with Me

For collaboration or questions, feel free to connect with me on LinkedIn!

ğŸ‘¤ Shaheer Ul IslamğŸ”— [My LinkedIn Profile](https://www.linkedin.com/in/shaheer-ul-islam-a135b2290/)

ğŸŒŸ Feel free to â­ this repository if you found it useful!

